{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JEM092 Asset Pricing\n",
    "# Seminar 8\n",
    "## Lukáš Petrásek\n",
    "### Charles University\n",
    "### lukas.petrasek@fsv.cuni.cz\n",
    "## 14.4.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "packages <- c(\"PerformanceAnalytics\", \"portsort\", \"quantmod\", \"readr\", \"sandwich\", \"xts\")\n",
    "\n",
    "# Install packages not yet installed\n",
    "installed_packages <- packages %in% rownames(installed.packages())\n",
    "if (any(installed_packages == FALSE)) {\n",
    "  install.packages(packages[!installed_packages])\n",
    "  print(paste(\"Installing package \", packages[!installed_packages],\"...\", sep = \"\"))\n",
    "}\n",
    "\n",
    "# Packages loading\n",
    "invisible(lapply(packages, library, character.only = TRUE))\n",
    "rm(list = ls()) #Clean environment\n",
    "\n",
    "# Miscellaneous\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)\n",
    "set.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load tickers.\n",
    "sp100_tickers <- read_csv(\n",
    "    'sp100_tickers.csv',\n",
    "    col_names = FALSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE <- '2011-01-01'\n",
    "END_DATE <- '2022-03-31'\n",
    "\n",
    "# Load stock prices and nominals.\n",
    "prices <- c()\n",
    "nominals <- c()\n",
    "for (i in 1:nrow(sp100_tickers)) {\n",
    "    ticker <- as.character(sp100_tickers[i, 1])\n",
    "    stock_data <- getSymbols(\n",
    "        ticker,\n",
    "        from = START_DATE,\n",
    "        to = END_DATE,\n",
    "        src = 'yahoo',\n",
    "        warnings = FALSE,\n",
    "        auto.assign = FALSE\n",
    "    )\n",
    "\n",
    "    stock_prices = stock_data[, 6]\n",
    "    stock_nominals = stock_data[, 5] * stock_prices\n",
    "    colnames(stock_prices) <- ticker\n",
    "    colnames(stock_nominals) <- ticker\n",
    "    prices <- cbind(prices, stock_prices)\n",
    "    nominals <- cbind(nominals, stock_nominals)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               AAPL ABBV      ABT\n",
       "2011-01-03 10.07865   NA 17.88170\n",
       "2011-01-04 10.13125   NA 18.04997\n",
       "2011-01-05 10.21413   NA 18.04997\n",
       "2011-01-06 10.20587   NA 18.01257\n",
       "2011-01-07 10.27896   NA 18.08737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                 AAPL ABBV       ABT\n",
       "2011-01-03 4486395916   NA 340650518\n",
       "2011-01-04 3131376400   NA 339815778\n",
       "2011-01-05 2609909901   NA 511583969\n",
       "2011-01-06 3066137878   NA 584886863\n",
       "2011-01-07 3206328328   NA 390767077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prices[1:5, 1:3]\n",
    "nominals[1:5, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\"Warning message in to_period(xx, period = on.opts[[period]], ...):\n",
      "\"missing values removed from data\""
     ]
    }
   ],
   "source": [
    "# Compute daily and quarterly returns.\n",
    "daily_returns <- lapply(prices, dailyReturn, USE.NAMES = TRUE)\n",
    "quarterly_returns <- lapply(prices, quarterlyReturn, USE.NAMES = TRUE)\n",
    "daily_returns <- do.call('cbind', daily_returns)\n",
    "quarterly_returns <- do.call('cbind', quarterly_returns)\n",
    "colnames(daily_returns) <- paste('dr', colnames(prices), sep = '_')\n",
    "colnames(quarterly_returns) <- paste('qr', colnames(prices), sep = '_')\n",
    "index(quarterly_returns) <- as.Date(as.yearqtr(index(quarterly_returns), format = \"Q%q/%y\"), frac = 1)\n",
    "\n",
    "# Compute quarterly volatilities.\n",
    "quarterly_volatilities <- as.xts(aggregate(daily_returns, as.yearqtr(as.yearmon(time(daily_returns))), sd))\n",
    "index(quarterly_volatilities) <- as.Date(as.yearqtr(index(quarterly_volatilities), format = \"Q%q/%y\"), frac = 1)\n",
    "colnames(quarterly_volatilities) <- paste('qv', colnames(prices), sep = '_')\n",
    "\n",
    "# Comupte quarterly nominals.\n",
    "quarterly_nominals <- as.xts(aggregate(nominals, as.yearqtr(as.yearmon(time(nominals))), sum))\n",
    "index(quarterly_nominals) <- as.Date(as.yearqtr(index(quarterly_nominals), format = \"Q%q/%y\"), frac = 1)\n",
    "colnames(quarterly_nominals) <- paste('qn', colnames(prices), sep = '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                qr_WMT       qr_XOM    qv_AAPL qv_ABBV      qv_ABT\n",
       "2011-03-31 -0.03931782  0.134451983 0.01444765      NA 0.008926913\n",
       "2011-06-30  0.02769657 -0.027201529 0.01259786      NA 0.007870223\n",
       "2011-09-30 -0.01626925 -0.101626420 0.01996506      NA 0.015505610\n",
       "2011-12-31  0.15863984  0.173964538 0.01810008      NA 0.010620595\n",
       "2012-03-31  0.03095107  0.028842575 0.01453347      NA 0.006767010\n",
       "2012-06-30  0.14694641 -0.006578129 0.02149117      NA 0.008578419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                qv_WMT     qv_XOM      qn_AAPL qn_ABBV      qn_ABT\n",
       "2011-03-31 0.009114307 0.01235016 331334273079      NA 22787641519\n",
       "2011-06-30 0.006809001 0.01147592 262299993200      NA 19580703148\n",
       "2011-09-30 0.014105862 0.02155496 451901399103      NA 21246560936\n",
       "2011-12-31 0.010266281 0.01617540 340115243510      NA 22952113944\n",
       "2012-03-31 0.008193055 0.00820063 541465866069      NA 20952391002\n",
       "2012-06-30 0.012796166 0.01154672 616844938337      NA 21596139114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the quarterly data.\n",
    "head(cbind(quarterly_returns, quarterly_volatilities, quarterly_nominals)[, 96:100])\n",
    "head(cbind(quarterly_returns, quarterly_volatilities, quarterly_nominals)[, 193:197])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio sorts\n",
    "\n",
    "Sorting procedure:\n",
    "\n",
    "1) Find breakpoints.\n",
    "\n",
    "2) Form portfolios.\n",
    "\n",
    "3) Average values within each portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate sorts\n",
    "\n",
    "Sorts are created based on a single variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: 3 months quintile portfolios based on nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    1         2         3         4         5       5 - 1\n",
       "2011-06-30         NA        NA        NA        NA        NA          NA\n",
       "2011-09-30         NA        NA        NA        NA        NA          NA\n",
       "2011-12-31 0.09585517 0.1435353 0.1379672 0.1294503 0.0504751 -0.04538006\n",
       "2012-03-31         NA        NA        NA        NA        NA          NA\n",
       "2012-06-30         NA        NA        NA        NA        NA          NA\n",
       "2012-09-30         NA        NA        NA        NA        NA          NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_portfolios <- 5\n",
    "diff_portfolio <- paste(n_portfolios, '- 1')\n",
    "\n",
    "# Initialize an xts object for storing portfolio returns.\n",
    "returns_nominals <- as.xts(\n",
    "    matrix(\n",
    "        nrow = nrow(quarterly_nominals) - 1,\n",
    "        ncol = n_portfolios + 1\n",
    "    ),\n",
    "    order.by = index(quarterly_nominals[2:nrow(quarterly_nominals)])\n",
    ")\n",
    "names(returns_nominals) <- c(1:n_portfolios, diff_portfolio)\n",
    "\n",
    "# Let's fix `i` so that we easily see what happens inside the first loop.\n",
    "i <- 3\n",
    "\n",
    "# Avoid look-ahead bias by sorting the returns after the quarter used to compute breakpoints ends.\n",
    "quarter_nominals <- quarterly_nominals[i]\n",
    "quarter_returns <- quarterly_returns[i + 1]\n",
    "\n",
    "breakpoints <- quantile(quarter_nominals, 0:n_portfolios/n_portfolios, na.rm = TRUE)\n",
    "not_na <- !is.na(quarter_nominals)\n",
    "\n",
    "for (j in 1:n_portfolios) {\n",
    "    filter <- (breakpoints[[j]] < quarter_nominals) & (quarter_nominals < breakpoints[[j + 1]]) & not_na\n",
    "    returns_nominals[i, j] <- mean(quarter_returns[, filter])\n",
    "}\n",
    "returns_nominals[i, diff_portfolio] <- returns_nominals[i, n_portfolios] - returns_nominals[i, 1]\n",
    "\n",
    "head(returns_nominals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in if (ncol(x) == 1) {: argument is of length zero\n",
     "output_type": "error",
     "traceback": [
      "Error in if (ncol(x) == 1) {: argument is of length zero\nTraceback:\n",
      "1. NeweyWest(model, lag = 4)",
      "2. vcovHAC(x, order.by = order.by, prewhite = prewhite, weights = myweights, \n .     adjust = adjust, diagnostics = diagnostics, sandwich = sandwich, \n .     ar.method = ar.method, data = data)",
      "3. vcovHAC.default(x, order.by = order.by, prewhite = prewhite, \n .     weights = myweights, adjust = adjust, diagnostics = diagnostics, \n .     sandwich = sandwich, ar.method = ar.method, data = data)",
      "4. meatHAC(x, order.by = order.by, prewhite = prewhite, weights = weights, \n .     adjust = adjust, diagnostics = diagnostics, ar.method = ar.method, \n .     data = data)",
      "5. estfun(x, ...)",
      "6. estfun.lm(x, ...)",
      "7. as.vector(res)",
      "8. as.vector(x, mode)",
      "9. as.vector.zoo(x, mode)",
      "10. as.vector(as.matrix(x), mode = mode)",
      "11. as.matrix(x)",
      "12. as.matrix.xts(x)"
     ]
    }
   ],
   "source": [
    "n_portfolios <- 5\n",
    "diff_portfolio <- paste(n_portfolios, '- 1')\n",
    "\n",
    "# Initialize an xts object for storing portfolio returns.\n",
    "returns_nominals <- as.xts(\n",
    "    matrix(\n",
    "        nrow = nrow(quarterly_nominals) - 1,\n",
    "        ncol = n_portfolios + 1\n",
    "    ),\n",
    "    order.by = index(quarterly_nominals[2:nrow(quarterly_nominals)])\n",
    ")\n",
    "names(returns_nominals) <- c(1:n_portfolios, diff_portfolio)\n",
    "\n",
    "# Iterate over rows, find breakpoints and compute quarterly returns within the given nominal bounds.\n",
    "for (i in 1:nrow(returns_nominals)) {\n",
    "    # Avoid look-ahead bias by sorting the returns after the quarter used to compute breakpoints ends.\n",
    "    quarter_nominals <- quarterly_nominals[i]\n",
    "    quarter_returns <- quarterly_returns[i + 1]\n",
    "\n",
    "    breakpoints <- quantile(quarter_nominals, 0:n_portfolios/n_portfolios, na.rm = TRUE)\n",
    "    not_na <- !is.na(quarter_nominals)\n",
    "\n",
    "    for (j in 1:n_portfolios) {\n",
    "        filter <- (breakpoints[[j]] < quarter_nominals) & (quarter_nominals < breakpoints[[j + 1]]) & not_na\n",
    "        returns_nominals[i, j] <- mean(quarter_returns[, filter])\n",
    "    }\n",
    "    returns_nominals[i, diff_portfolio] <- returns_nominals[i, n_portfolios] - returns_nominals[i, 1]\n",
    "}\n",
    "\n",
    "# Compute overall average returns within portfolios and their standard errors.\n",
    "results_nominals <- as.data.frame(matrix(nrow = 2, ncol = n_portfolios + 1))\n",
    "names(results_nominals) <- c(1:n_portfolios, diff_portfolio)\n",
    "for (i in 1:ncol(results_nominals)) {\n",
    "    model <- lm(returns_nominals[, i] ~ 1)\n",
    "    results_nominals[1, i] <- model$coefficients[[1]]\n",
    "    results_nominals[2, i] <- model$coefficients[[1]] / sqrt(NeweyWest(model, lag = 4))[[1]]\n",
    "}\n",
    "\n",
    "results_nominals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: 3 months quintile portfolios based on volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in if (ncol(x) == 1) {: argument is of length zero\n",
     "output_type": "error",
     "traceback": [
      "Error in if (ncol(x) == 1) {: argument is of length zero\nTraceback:\n",
      "1. NeweyWest(model, lag = 4)",
      "2. vcovHAC(x, order.by = order.by, prewhite = prewhite, weights = myweights, \n .     adjust = adjust, diagnostics = diagnostics, sandwich = sandwich, \n .     ar.method = ar.method, data = data)",
      "3. vcovHAC.default(x, order.by = order.by, prewhite = prewhite, \n .     weights = myweights, adjust = adjust, diagnostics = diagnostics, \n .     sandwich = sandwich, ar.method = ar.method, data = data)",
      "4. meatHAC(x, order.by = order.by, prewhite = prewhite, weights = weights, \n .     adjust = adjust, diagnostics = diagnostics, ar.method = ar.method, \n .     data = data)",
      "5. estfun(x, ...)",
      "6. estfun.lm(x, ...)",
      "7. as.vector(res)",
      "8. as.vector(x, mode)",
      "9. as.vector.zoo(x, mode)",
      "10. as.vector(as.matrix(x), mode = mode)",
      "11. as.matrix(x)",
      "12. as.matrix.xts(x)"
     ]
    }
   ],
   "source": [
    "# Choose the number of portfolios.\n",
    "n_portfolios <- 5\n",
    "diff_portfolio <- paste(n_portfolios, '- 1')\n",
    "\n",
    "# Initialize an xts object for storing portfolio returns.\n",
    "returns_volatilities <- as.xts(\n",
    "    matrix(\n",
    "        nrow = nrow(quarterly_volatilities) - 1,\n",
    "        ncol = n_portfolios + 1\n",
    "    ),\n",
    "    order.by = index(quarterly_volatilities[2:nrow(quarterly_volatilities)])\n",
    ")\n",
    "names(returns_volatilities) <- c(1:n_portfolios, diff_portfolio)\n",
    "\n",
    "# Iterate over rows, find breakpoints and compute quarterly returns within the given volatility bounds.\n",
    "for (i in 1:nrow(returns_volatilities)) {\n",
    "    # Avoid look-ahead bias by sorting the returns after the quarter used to compute breakpoints ends.\n",
    "    quarter_volatilities <- quarterly_volatilities[i]\n",
    "    quarter_returns <- quarterly_returns[i + 1]\n",
    "\n",
    "    breakpoints <- quantile(quarter_volatilities, 0:n_portfolios/n_portfolios, na.rm = TRUE)\n",
    "    not_na <-  !is.na(quarter_volatilities)\n",
    "\n",
    "    for (j in 1:n_portfolios) {\n",
    "        filter <- (breakpoints[[j]] < quarter_volatilities) & (quarter_volatilities < breakpoints[[j + 1]]) & not_na\n",
    "        returns_volatilities[i, j] <- mean(quarter_returns[, filter])\n",
    "    }\n",
    "    returns_volatilities[i, diff_portfolio] <- returns_volatilities[i, n_portfolios] - returns_volatilities[i, 1]\n",
    "}\n",
    "\n",
    "# Compute overall average returns within portfolios and their standard errors.\n",
    "results_volatilities <- as.data.frame(matrix(nrow = 2, ncol = n_portfolios + 1))\n",
    "names(results_volatilities) <- c(1:n_portfolios, diff_portfolio)\n",
    "for (i in 1:ncol(results_volatilities)) {\n",
    "    model <- lm(returns_volatilities[, i] ~ 1)\n",
    "    results_volatilities[1, i] <- model$coefficients[[1]]\n",
    "    results_volatilities[2, i] <- model$coefficients[[1]] / sqrt(NeweyWest(model, lag = 4))[[1]]\n",
    "}\n",
    "\n",
    "results_volatilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate sorts\n",
    "\n",
    "Sorts are created based on a two variables.\n",
    "\n",
    "### Example: 4 * 3 portfolios based on returns and volumes\n",
    "\n",
    "Let's follow the example in the documentation of the `portsort` package.\n",
    "\n",
    "#### Independent sorts\n",
    "\n",
    "Breakpoints of both variables are independent (computed on all observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, load the pre-loaded data.\n",
    "data(Factors)\n",
    "\n",
    "# Leading returns, lagged returns, and lagged volumes are stored in the Factors list.\n",
    "R.Forward <- Factors[[1]]\n",
    "R.Lag <- Factors[[2]]\n",
    "V.Lag <- Factors[[3]]\n",
    "Fa <- R.Lag\n",
    "Fb <- V.Lag\n",
    "\n",
    "# Specify the dimension of the sort - let's use quartiles and terciles.\n",
    "dimA <- 0:4/4\n",
    "dimB <- 0:3/3\n",
    "dimC <- c(0,1)\n",
    "\n",
    "# Run the unconditional sort with quantiles computed using method 7 from the quantile function (stats package).\n",
    "sort.output.uncon <- unconditional.sort(Fa, Fb, Fc = NULL, R.Forward, dimA, dimB, dimC, type = 7)\n",
    "\n",
    "# Compare the risk and return of each sub-portfolio using PerformanceAnalytics.\n",
    "# Set the scale to 365 (Cryptocurrency markets have no close) and geometric to FALSE (we are using log returns).\n",
    "table.AnnualizedReturns(sort.output.uncon$returns, scale = 365, geometric = FALSE, digits = 3)\n",
    "\n",
    "# Following the methodology of Gargano et al. 2017 and Bianchi and Dickerson (2018), we will now form a long-short, \n",
    "# zero-cost portfolio which initiates a long position in the low prior return/low volume sub-portfolio (sub-portfolio\n",
    "# 1) and a short position in the low return/high volume sub-portfolio (sub-portfolio 9).\n",
    "ls_portfolio.uncon = sort.output.uncon$returns[, 1] + (-1 * sort.output.uncon$returns[, 9])\n",
    "colnames(ls_portfolio.uncon) = c('Unonditional')\n",
    "\n",
    "# Plot the logarithmic cumulative returns.\n",
    "chart.CumReturns(ls_portfolio.uncon, geometric = FALSE, legend.loc = 'topleft')\n",
    "\n",
    "# Investigate risk and return.\n",
    "table.AnnualizedReturns(ls_portfolio.uncon, scale = 365, geometric = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependent sorts\n",
    "\n",
    "Breakpoints of the second sort variable are computed on observations within each group formed based on the first sort variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the conditional sort with quantiles computed using method 7 from the quantile function (stats package).\n",
    "sort.output.con <- conditional.sort(Fa, Fb, Fc = NULL, R.Forward, dimA, dimB, dimC, type = 7)\n",
    "\n",
    "# Compare the risk and return of each sub-portfolio using PerformanceAnalytics.\n",
    "# Set the scale to 365 (Cryptocurreny markets have no close) and geometric to FALSE (we are using log returns).\n",
    "table.AnnualizedReturns(sort.output.con$returns, scale = 365, geometric = FALSE, digits = 3)\n",
    "\n",
    "# Following the methodology of Gargano et al. 2017 and Bianchi and Dickerson (2018), we will now form a long-short, \n",
    "# zero-cost portfolio which initiates a long position in the low prior return/low volume sub-portfolio (sub-portfolio\n",
    "# 1) and a short position in the low return/high volume sub-portfolio (sub-portfolio 9).\n",
    "ls_portfolio.con = sort.output.con$returns[, 1] + (-1 * sort.output.con$returns[, 9])\n",
    "colnames(ls_portfolio.con) = c('Conditional')\n",
    "\n",
    "# Plot the logarithmic cumulative returns.\n",
    "chart.CumReturns(ls_portfolio.con, geometric = FALSE, legend.loc = 'topleft')\n",
    "\n",
    "# Investigate risk and return.\n",
    "table.AnnualizedReturns(ls_portfolio.con, scale = 365, geometric = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = cbind(ls_portfolio.con, ls_portfolio.uncon)\n",
    "colnames(portfolios) = c('Conditional', 'Unconditional')\n",
    "\n",
    "# Plot the logarithmic cumulative returns.\n",
    "chart.CumReturns(portfolios, geometric = FALSE, legend.loc = 'topleft', main = 'Sorting Comparison')\n",
    "\n",
    "# Investigate risk and return.\n",
    "table.AnnualizedReturns(portfolios,scale = 365, geometric = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next time: Fama-MacBeth regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quoting from the fama-macbeth package documentation:\n",
    "\n",
    "Theories of asset pricing frequently use 'risk factors' to explain asset returns. These factors can range from macroeconomic (for example, consumer inflation or the unemployment rate) to financial (firm size, etc). The Fama-MacBeth two-step regression is a practical way of testing how these factors describe portfolio or asset returns. The goal is to find the premium from exposure to these factors. In the first step, each portfolio's return is regressed against one or more factor time series to determine how exposed it is to each one (the 'factor exposures'). In the second step, the cross-section of portfolio returns is regressed against the factor exposures, at each time step, to give a time series of risk premia coefficients for each factor. The insight of Fama-MacBeth is to then average these coefficients, once for each factor, to give the premium expected for a unit exposure to each risk factor over time.\n",
    "\n",
    "In equation form, for $n$ portfolio or asset returns and $m$ factors, in the first step the factor exposure $\\beta$s are obtained by calculating $n$ regressions, each one on $m$ factors (each equation in the following represents a regression):\n",
    "$$R_{1,t} = \\alpha_1 + \\beta_{1,F_1} F_{1,t} + \\beta_{1,F_2} F_{2,t} + . . . + \\beta_{1,F_m} F_{m,t} + \\epsilon_{1,t}$$\n",
    "$$R_{2,t} = \\alpha_2 + \\beta_{2,F_1} F_{1,t} + \\beta_{2,F_2} F_{2,t} + . . . + \\beta_{2,F_m} F_{m,t} + \\epsilon_{2,t}$$\n",
    ".\n",
    ".\n",
    ".\n",
    "$$R_{n,t} = \\alpha_n + \\beta_{n,F_1} F_{1,t} + \\beta_{n,F_2} F_{2,t} + . . . + \\beta_{n,F_m} F_{m,t} + \\epsilon_{n,t}$$\n",
    "where $R_{i,t}$ is the return of portfolio or asset $i$ ($n$ total) at time $t$, $F_{j,t}$ is the factor $j$ ($m$ total) at time $t$, $\\beta_{i,F_m}$ are the factor exposures, or loadings, that describe how returns are exposed to the factors, and $t$ goes from $1$ through $T$. Notice that each regression uses the same factors $F$, because the purpose is to determine the exposure of each portfolio's return to a given set of factors.\n",
    "\n",
    "The second step is to compute $T$ cross-sectional regressions of the returns on the $m$ estimates of the $\\beta$s (call then $\\hat{\\beta}$) calculated from the first step. Notice that each regression uses the same $\\beta$s from the first step, because now the goal is the exposure of the $n$ returns to the $m$ factor loadings over time (e.g., does a larger factor exposure mean a higher return?):\n",
    "$$R_{i,1} = \\gamma_{1,0} + \\gamma_{1,1} \\hat{\\beta}_{i,F_1} + + \\gamma_{1,2} \\hat{\\beta}_{i,F_2} + . . . + + \\gamma_{1,m} \\hat{\\beta}_{i,F_m} + \\epsilon_{i,1}$$\n",
    "$$R_{i,2} = \\gamma_{2,0} + \\gamma_{2,1} \\hat{\\beta}_{i,F_1} + + \\gamma_{2,2} \\hat{\\beta}_{i,F_2} + . . . + + \\gamma_{2,m} \\hat{\\beta}_{i,F_m} + \\epsilon_{i,2}$$\n",
    ".\n",
    ".\n",
    ".\n",
    "$$R_{i,T} = \\gamma_{T,0} + \\gamma_{1,1} \\hat{\\beta}_{i,F_1} + + \\gamma_{T,2} \\hat{\\beta}_{i,F_2} + . . . + + \\gamma_{T,m} \\hat{\\beta}_{i,F_m} + \\epsilon_{i,T}$$\n",
    "where the returns $R$ are the same as those in the first step equations, $\\gamma$ are regression coefficients that are later used to calculate the risk premium for each factor, and in each regression $i$ goes from $1$ through $n$.\n",
    "\n",
    "In the end there are $m + 1$ series $\\gamma$ (including the constant in the second step) for every factor, each of length $T$. If the $\\epsilon$ are assumed to be i.i.d, calculate the risk premium $\\gamma_m$ for factor $F_m$ by averaging the $m$th $\\gamma$ over $T$, and also get standard deviations and t-stats. For example, t-stats for the mth risk premium are:\n",
    "$$\\frac{\\gamma_m}{\\sigma_{\\gamma_m} / \\sqrt{T}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
